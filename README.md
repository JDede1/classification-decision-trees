Got it âœ… â€” hereâ€™s a polished `README.md` for your repo that directly references your 
# Assignment 4: Classification â€“ Decision Trees

## Overview
This project is part of the **University of Arizona â€“ Masterâ€™s Coursework**.  
In this assignment, we build and evaluate a **Decision Tree Classifier** to predict whether a victim in the *Fatal Police Shootings* dataset showed **signs of mental illness**.  

We then **regularize (prune)** the decision tree and compare its performance before and after pruning.

The implementation, questions, and solutions are documented in the Jupyter Notebook:  
ðŸ““ **`classification_task_decision_trees.ipynb`**

---

## Dataset
The dataset used is **`fatal-police-shootings-data.csv`**, which contains details of fatal police shootings in the U.S.  

### Columns
1. **id** â€“ unique identifier of each victim  
2. **name** â€“ name of a victim  
3. **date** â€“ date of fatal shooting  
4. **manner_of_death** â€“ `Shot`, `Shot and Tasered`  
5. **armed** â€“ weapon information (`undetermined`, `unknown`, `unarmed`)  
6. **age** â€“ age of victim  
7. **gender** â€“ `M`, `F`, or `None` (unknown)  
8. **race** â€“ `W`, `B`, `A`, `N`, `H`, `O`, or `None`  
9. **city** â€“ location of incident  
10. **state** â€“ two-letter postal code abbreviation  
11. **signs_of_mental_illness** â€“ target variable (`True` / `False`)  
12. **threat_level** â€“ incident threat level (`attack`, `other`, `undetermined`)  
13. **flee** â€“ `Foot`, `Car`, `Not fleeing`  
14. **body_camera** â€“ whether body camera footage exists  

---

## Objectives
- Handle missing values and clean the dataset.  
- Encode categorical variables for model training.  
- Build a **Decision Tree Classifier** using `scikit-learn`.  
- Evaluate the model using accuracy and confusion matrix.  
- Visualize the decision tree using Graphviz.  
- **Regularize (prune)** the tree by tuning parameters (`max_depth`, `min_samples_split`, etc.) to prevent overfitting.  
- Compare train/test accuracy and feature importances before and after pruning.  

---

## Steps to Run

### 1. Clone this repo
```bash
git clone git@github.com:JDede1/classification-decision-trees.git
cd classification-decision-trees
````

### 2. Create virtual environment

```bash
python -m venv .venv
.venv\Scripts\Activate   # Windows PowerShell
# OR
source .venv/bin/activate   # Mac/Linux
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Launch Jupyter Notebook

```bash
jupyter notebook
```

Open `Assignment4_DecisionTrees.ipynb` and run the cells.

---

## Tools & Libraries

* Python 3
* pandas, numpy
* scikit-learn (DecisionTreeClassifier, metrics, model\_selection)
* matplotlib, seaborn
* Jupyter Notebook

> For exporting `.dot` â†’ `.png`, you may need **Graphviz** installed:
>
> ```bash
> sudo apt-get install graphviz   # Linux
> choco install graphviz          # Windows (Chocolatey)
> ```

---

## Results

* A fully grown decision tree tends to **overfit** (high train accuracy, lower test accuracy).
* A **regularized (pruned)** decision tree generalizes better and improves test performance.
* Feature importance analysis shows which predictors contribute most to detecting mental illness signs.

---
